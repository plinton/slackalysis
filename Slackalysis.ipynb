{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import slacker\n",
    "s = slacker.Slacker(\"\") # Slack api key goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "# setup, import modules\n",
    "import mpld3\n",
    "\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "import stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "\n",
    "mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_response = slacker.channels.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json.dump(channel_response.body, open(\"data/channel_data.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channels = json.load(open(\"data/channel_data.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channel_to_message = json.load(open(\"channel_message.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channels = channel_response.body[\"channels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pylab.hist([len(x[\"members\"]) for x in channels], bins=range(0, 1500, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the number of channels per member, then display it as a histogram\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "channels_per_member = Counter(itertools.chain.from_iterable(channel[\"members\"] for channel in channels if not channel.get(\"is_general\", False)))\n",
    "pylab.hist([x[1] for x in channels_per_member.items() if x[0] not in irregular_users], bins=range(105))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collect all of the channels and all of the messages (in order) in that channel.\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "Message = namedtuple(\"Message\", [\"channel\", \"subtype\", \"user\", \"time_sent\", \"message\"])\n",
    "\n",
    "\n",
    "channel_to_message = defaultdict(list) \n",
    "for channel in channels:\n",
    "    print \"started channel\", channel[\"name\"]\n",
    "    has_more = True\n",
    "    latest = time.time()\n",
    "    while has_more:\n",
    "        history_response = s.channels.history(channel[\"id\"], latest=latest, count=1000)\n",
    "        for message in history_response.body[\"messages\"]:\n",
    "            channel_to_message[channel[\"name\"]].append(message)\n",
    "        has_more = history_response.body[\"has_more\"]\n",
    "        if has_more:\n",
    "            latest = message[\"ts\"]\n",
    "    print \"finished channel\", channel[\"name\"]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_response = s.users.list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json.dump(users_response.body, open(\"data/user_data.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Some useful user groupings and data structures\n",
    "\n",
    "user_ids_to_names = {x[\"id\"]: x[\"name\"] for x in users_response.body[\"members\"]}\n",
    "user_names_to_ids = {x[\"name\"]: x[\"id\"] for x in users_response.body[\"members\"]}\n",
    "restricted_users = {x[\"id\"] for x in users_response.body[\"members\"] if x.get(\"is_restricted\", False)}\n",
    "ultra_restricted_users = {x[\"id\"] for x in users_response.body[\"members\"] if x.get(\"is_ultra_restricted\", False)}\n",
    "bots = {x[\"id\"] for x in users_response.body[\"members\"] if x.get(\"is_bot\", False)}\n",
    "irregular_users = restricted_users | ultra_restricted_users | bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"total regular (non-restricted, non-ultra-restricted, non-bot) users:\", len([x for x in users_response.body[\"members\"] if x[\"id\"] not in irregular_users])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channels_per_regular_user = Counter({x[0]: x[1] for x in channels_per_member.items() if x[0] not in irregular_users})\n",
    "most_channels = [(user_ids_to_names[x[0]], x[1]) for x in channels_per_regular_user.most_common(15)]\n",
    "\n",
    "average_num_channels = sum(channels_per_regular_user.values())/len(channels_per_regular_user)\n",
    "median_num_channels = sorted(channels_per_regular_user.values())[len(channels_per_regular_user)/2]\n",
    "mode_num_channels = Counter(channels_per_regular_user.values()).most_common(1)[0]\n",
    "print \"users with the most channels: \", most_channels\n",
    "print \"average number of channels:\", average_num_channels\n",
    "print \"median number of channels:\", median_num_channels\n",
    "print \"mode number of channels: {} (with {} users)\".format(mode_num_channels[0], mode_num_channels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"largest channels: \", sorted([(len(values), key) for (key, values) in channel_to_message.items()], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The next few cells are an experiment to try to get topics per channel. Not very effective yet.\n",
    "\n",
    "import nltk\n",
    "import stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "\n",
    "chan_to_text = {}\n",
    "texts = []\n",
    "\n",
    "for i, (channel, messages) in enumerate(channel_to_message.iteritems()):\n",
    "    text = []\n",
    "    for message in messages:\n",
    "        if \"subtype\" not in message and not message[\"text\"].startswith(\"/\"):\n",
    "            text.extend(tokenize(message[\"text\"]))\n",
    "    chan_to_text[channel] = text\n",
    "    if i and not i % 100:\n",
    "        print \"finished {} of {}\".format(i, len(channel_to_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dictionary = corpora.Dictionary(chan_to_text.values())\n",
    "\n",
    "print \"made dictionary\"\n",
    "chan_to_bow = {channel: dictionary.doc2bow(texts) for channel, texts in chan_to_text.iteritems()}\n",
    "print \"made chan_to_bow\"\n",
    "# generate LDA model\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(chan_to_bow.values(), num_topics=300, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en_words = set(stop_words.get_stop_words('en'))\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "import re\n",
    "punct_pattern = r\"\"\n",
    "link_pattern = r\"<[^\\s]+>:?\"\n",
    "emoji_pattern = r\":[^\\s]+:\"\n",
    "whitespace_condenser = re.compile(r\"\\s+\")\n",
    "matcher = re.compile(\"|\".join([link_pattern, emoji_pattern]))\n",
    "def tokenize(message):\n",
    "    subbed = matcher.sub(\"\", message.lower())\n",
    "    condensed = whitespace_condenser.sub(\" \", subbed)\n",
    "    stopped = (x for x in condensed.split() if x and x not in en_words)\n",
    "    return list(stopped)#[p_stemmer.stem(x) for x in stopped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(dictionary[topic], value) for topic, value in ldamodel[chan_to_bow[\"general\"]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "for message in channel_to_message[\"general\"]:\n",
    "    if \"subtype\" not in message and not message[\"text\"].startswith(\"/\"):\n",
    "        texts.append(tokenize(message[\"text\"]))\n",
    "dictionary_swift = corpora.Dictionary(texts)\n",
    "ldamodel_swift = gensim.models.ldamodel.LdaModel([dictionary_swift.doc2bow(text) for text in texts], num_topics=10, id2word=dictionary_swift, passes=20)\n",
    "ldamodel_swift.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gensim.models.ldamodel.LdaModel([dictionary_kiwi.doc2bow(text) for text in texts], num_topics=10, id2word=dictionary_kiwi, passes=20).show_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for message in channel_to_message[\"general\"][:15]:\n",
    "    if \"subtype\" not in message and not message['text'].startswith(\"/\"):\n",
    "        message = message[\"text\"]\n",
    "        subbed = matcher.sub(\"\", message.lower())\n",
    "        condensed = whitespace_condenser.sub(\" \", subbed)\n",
    "        stopped = [x for x in condensed.split() if x and x not in en_words]\n",
    "        stemmed = [p_stemmer.stem(x) for x in stopped]\n",
    "        print message\n",
    "        print subbed\n",
    "        print condensed\n",
    "        print stopped\n",
    "        print stemmed\n",
    "        print \"---------------\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
